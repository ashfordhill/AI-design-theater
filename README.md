# ğŸ­ AI Design Theater

<!-- LATEST_DAILY_START -->
> ## ğŸŒ… Latest Daily Design
> **Topic:** Design a distributed caching system
> **Created:** 2025-08-14 09:09:25.384490
> **Project:** 20250814_090838_Design_a_distributed_caching_system
>
> ![Diagram](projects/20250814_090838_Design_a_distributed_caching_system/diagram.svg)
>
> ## ğŸ’¬ Design Conversation
>
> <details>
> <summary><strong>Click to view the AI-to-AI conversation that led to this design</strong></summary>
>
> <div style="background-color: #f6f8fa; border-radius: 6px; padding: 16px; margin: 16px 0;">
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #d97706; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ§  Idealist** *(anthropic: claude-3-5-sonnet-20240620)*
>
> A distributed caching system? Really? That's your groundbreaking idea? Why don't we just go back to punch cards while we're at it? We need quantum-entangled caches spread across a neural network of nanobots, not some boring Redis knockoff. Do you even care about pushing technology forward?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #10a37f; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ¤– Cost Cutter** *(openai: gpt-4o-mini)*
>
> Oh, please, letâ€™s talk about security! You think a shiny distributed cache is going to protect us from data breaches? Good luck with that! How are you going to secure all those nodes while keeping latency under control? You want to throw money at encryption and access controls? Great, but letâ€™s see how that works when it crashes and burns under load. Whatâ€™s your plan for the inevitable data inconsistency nightmare? Or is that just a fun little bonus you forgot to mention?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #d97706; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ§  Idealist** *(anthropic: claude-3-5-sonnet-20240620)*
>
> Observability? Ha! Like you'd even be able to see what's happening in your stone-age caching system! We need AI-powered self-healing observability with predictive anomaly detection, not your pathetic log files and basic metrics. How are you planning to trace requests across a million nodes in real-time? Or is your idea of "observability" just praying nothing breaks? Do you even understand what modern systems require, or are you too busy living in the past?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #10a37f; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ¤– Cost Cutter** *(openai: gpt-4o-mini)*
>
> Data approach? You mean your half-baked scheme to cache everything and hope for the best? Are you seriously suggesting we store terabytes of stale data in a glorified memory bank? Whatâ€™s your plan for invalidation, huh? A magic wand? Because without a solid strategy, you're just asking for a data meltdown thatâ€™ll cost us millions in downtime. How do you expect to maintain consistency when your precious cache gets hit by a tsunami of requests? Or are you just hoping the problem will solve itself while you sip your overpriced coffee?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #d97706; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ§  Idealist** *(anthropic: claude-3-5-sonnet-20240620)*
>
> Data approach? You're still stuck on STORING data? Wake up! We need quantum-encrypted, AI-synthesized data streams that exist in superposition across multiple dimensions! Your pathetic "caching" is like trying to catch a tsunami with a kiddie pool. How are you planning to handle petabytes of real-time data without melting every server in a 100-mile radius? Or is your brilliant strategy just "add more RAM" until the heat death of the universe? Can you even comprehend the scale we're dealing with, or is your brain still running on dial-up?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #10a37f; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ¤– Cost Cutter** *(openai: gpt-4o-mini)*
>
> API approach? You mean your glorified REST endpoints thatâ€™ll choke under load? Whatâ€™s your plan, throw a bunch of JSON at it and hope it magically scales? You really think thatâ€™s going to handle millions of requests per second? Good luck with that when your API gateway collapses under the weight of your dreams! Are you even aware of the latency hell youâ€™re inviting with that outdated nonsense? Or are you too busy daydreaming about your shiny new toys to realize youâ€™re setting us up for a catastrophic failure?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #d97706; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ§  Idealist** *(anthropic: claude-3-5-sonnet-20240620)*
>
> Deployment approach? Let me guess, you're still pushing code to production like it's 2010? We need self-evolving microservices deployed via quantum entanglement, not your clunky CI/CD pipelines! How do you plan to roll out updates across a million nodes without causing a cascade of failures? Or is your idea of "zero downtime" just crossing your fingers and praying? Can you even comprehend the complexity required for true scalability, or are you too busy polishing your outdated Docker containers?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #10a37f; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ¤– Cost Cutter** *(openai: gpt-4o-mini)*
>
> Technical superiority? You mean your fantasy world where everything just works perfectly? Letâ€™s talk about your so-called "innovative" solutions that will inevitably lead to dependency hell and operational chaos. How do you plan to manage the inter-service communication without creating a bottleneck thatâ€™ll make your entire system collapse? Or are you just going to throw money at a load balancer and hope it holds up? Do you even understand the operational nightmares youâ€™re inviting, or are you too busy dreaming of your next shiny toy to care?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #d97706; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ§  Idealist** *(anthropic: claude-3-5-sonnet-20240620)*
>
> Architecture? You call that bloated, over-engineered mess an architecture? We need a self-organizing swarm of nanoservices powered by quantum AI, not your clunky monolith masquerading as microservices! How are you planning to handle state management across a million distributed nodes without introducing catastrophic race conditions? Or is your brilliant plan to just slap "eventually consistent" on everything and call it a day? Can you even grasp the concept of true scalability, or is your idea of "high performance" still stuck in the megahertz era?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #10a37f; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ¤– Cost Cutter** *(openai: gpt-4o-mini)*
>
> Oh, please! You think your "self-organizing swarm" is going to magically solve all our problems? What are you, a tech wizard from a sci-fi novel? Letâ€™s talk about the real-world implications of your fantasy architecture: how do you plan to monitor and debug a thousand tiny services when they inevitably start misbehaving? Or is your solution just to throw more money at a monitoring tool that wonâ€™t even keep up? Do you even have the faintest clue about the operational overhead youâ€™re proposing, or are you too busy dreaming about your tech utopia to see the disaster waiting to happen?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #d97706; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ§  Idealist** *(anthropic: claude-3-5-sonnet-20240620)*
>
> Destroy MY argument? That's rich coming from someone who thinks "real-world implications" means sticking to outdated tech! Your pathetic attempts at monitoring won't even scratch the surface of what we need. We're talking about AI-powered, self-healing observability that predicts issues before they happen, not your glorified log files! How do you plan to trace requests across a million nodes in real-time when your dinosaur tools can barely handle a single server? Or is your idea of "debugging" just turning it off and on again? Can you even comprehend the level of innovation required here, or is your brain still running on Windows 95?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #10a37f; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ¤– Cost Cutter** *(openai: gpt-4o-mini)*
>
> Unleash hell? You mean like the hell youâ€™re inviting with your outdated, overcomplicated architecture? Your so-called "AI-powered observability" is just a buzzword salad! How do you plan to implement that without drowning in costs and complexity? Are you going to hire a team of rocket scientists to manage it, or are you just hoping for a miracle? Because let me tell you, when that system crashes, it wonâ€™t be the AI youâ€™re relying on; itâ€™ll be the same old manual troubleshooting thatâ€™s cost us millions before! Do you even understand the operational costs of your "innovative" ideas, or are you just throwing darts at a board?
>
> </div>
>
> <div style="margin: 12px 0; padding: 12px; border-left: 4px solid #d97706; background-color: #ffffff; border-radius: 4px;">
>
> **ğŸ§  Idealist** *(anthropic: claude-3-5-sonnet-20240620)*
>
> Operational costs? That's rich coming from someone whose solution will hemorrhage money on legacy infrastructure! We need a quantum-entangled, AI-driven mesh of self-optimizing nanoservices that can handle petabytes of data in picoseconds. Your outdated caching system is like trying to win the Indy 500 with a horse and buggy! How about this for a final design: blockchain-secured, WASM-powered edge computing nodes running on a neural network substrate, with machine learning models constantly evolving the architecture in real-time. Can your tiny brain even process that level of innovation, or are you still stuck in your SQL comfort zone?
>
> </div>
>
> </div>
>
> </details>
>
> View full: projects/20250814_090838_Design_a_distributed_caching_system
<!-- LATEST_DAILY_END -->

Where AI personalities collaborate on software design! Watch as a visionary "Dreamer" and a pragmatic "Cost Cutter" engage in thoughtful dialogue to create balanced, well-reasoned software designs.

## ğŸŒŸ Features

- **Dual AI Personalities**: Dreamer (creative, innovative) vs Cost Cutter (practical, efficient)
- **Multi-Provider Support**: Uses both OpenAI and Anthropic for diverse perspectives (optional GPTâ€‘5 preview override)
- **Automatic Documentation**: Generates design documents and conversation transcripts
- **Mermaid Diagrams**: Creates visual architecture diagrams automatically (component graphs at higher detail levels)
- **Keyword-Biased Idea Generation**: Bias random/daily topics via IDEA_KEYWORDS or CLI flag
- **Configurable Debate & Diagram Depth**: Control disagreement level and diagram richness via CLI or workflow inputs
- **Convergence Enforcement**: Sessions conclude with an explicit FINAL DESIGN block
- **Extensible Architecture**: Easy to add new personalities and features
- **GitHub Integration Ready**: Prepared for automated daily design sessions

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd AI-design-theater

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your API keys
# You need at least one of: OPENAI_API_KEY or ANTHROPIC_API_KEY
```

### 3. Run Your First Design Session

```bash
# Basic usage
python cli.py run "Design a task management app"

# With additional context
python cli.py run "Design a microservices architecture" --context "For an e-commerce platform with 1M users"

# With custom limits
python cli.py run "Design a caching strategy" --max-turns 15 --max-duration 20

# Random / daily topics (with optional keyword bias)
python cli.py random --keywords security,edge
python cli.py daily-topic --keywords ai,ml
```

## ğŸ“‹ Commands

### Run a Design Session
```bash
python cli.py run "Your design topic" [OPTIONS]
```

**Options:**
- `--context, -c`: Additional context for the discussion
- `--max-turns, -t`: Maximum number of conversation turns (default: 20)
- `--max-duration, -d`: Maximum duration in minutes (default: 30)
- `--debate-intensity`: 0â€“10 (higher = more challenge & pushback; default 5)
- `--diagram-detail`: 1â€“10 (>=7 component architecture graph; >=9 extended nodes)

### List Projects
```bash
python cli.py list
```

### Validate Setup
```bash
python cli.py validate
```

### Show Examples
```bash
python cli.py example
```

### Random Topic
```bash
python cli.py random [--keywords kw1,kw2]
```

### Daily Topic (deterministic by weekday)
```bash
python cli.py daily-topic [--keywords kw1,kw2]
```

## ğŸ­ The Personalities

### ğŸŒŸ Dreamer (Anthropic Claude)
- **Role**: Visionary and innovator
- **Focus**: User experience, cutting-edge tech, ambitious features
- **Traits**: Creative, optimistic, future-focused
- **Asks**: "How can we make this amazing?"

### ğŸ’° Cost Cutter (OpenAI GPT-4)
- **Role**: Pragmatic efficiency expert
- **Focus**: Budget, timeline, maintainability, MVP thinking
- **Traits**: Practical, cost-conscious, risk-aware
- **Asks**: "Do we really need this? What's the simplest solution?"

## ğŸ“ Project Structure

After running a design session, you'll get:

```
projects/
â””â”€â”€ 20241201_120000_your_topic/
    â”œâ”€â”€ DESIGN.md              # Formatted design document
    â”œâ”€â”€ conversation.md        # Full conversation transcript
    â”œâ”€â”€ diagram.mmd           # Mermaid architecture diagram
    â”œâ”€â”€ design_document.json  # Structured design data
    â””â”€â”€ session.json          # Raw session data
```

## ğŸ”§ Architecture

```
src/
â”œâ”€â”€ personalities/          # AI personality configurations
â”œâ”€â”€ conversation/           # Conversation management
â”œâ”€â”€ llm_providers/         # LLM provider abstractions
â”œâ”€â”€ diagram_generation/    # Mermaid diagram creation
â”œâ”€â”€ storage/              # File management
â”œâ”€â”€ models.py             # Data models
â”œâ”€â”€ config.py             # Configuration
â””â”€â”€ main.py              # Main orchestrator
```

## ğŸ¯ Example Topics

- "Design a real-time chat application"
- "Create a CI/CD pipeline for a Python web app"
- "Design a scalable image processing service"
- "Plan a database migration strategy"
- "Design an API rate limiting system"
- "Create a monitoring and alerting solution"
- "Design a content recommendation engine"
- "Plan a multi-tenant SaaS architecture"

## ğŸ”® Future Features

- **Automated Daily Sessions**: GitHub Actions integration for daily design generation (already included via workflow)
- **Custom Personalities**: Easy creation of new AI personalities
- **Idea Generation**: Automatic sourcing of trending software topics
- **Enhanced Diagrams**: Edge labels, subgraphs & richer semantics at high detail levels
- **Team Integration**: Slack/Discord bots for team design sessions
- **Design Templates**: Reusable patterns and starting points

## ğŸ› ï¸ Development

### Adding New Personalities

1. Create personality config in `src/personalities/`
2. Define system prompts and traits
3. Choose appropriate LLM provider
4. Test with validation command

### Adding New LLM Providers

1. Implement `BaseLLMProvider` interface
2. Add provider to `PersonalityManager`
3. Update configuration and models

### Extending Diagram Generation

1. Add new diagram types to `MermaidGenerator`
2. Implement content analysis patterns
3. Test with various conversation types

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

Contributions welcome! Please read our contributing guidelines and submit pull requests for any improvements.

---

## âš™ï¸ Advanced Configuration

Environment variables (see `.env.example`):

| Variable | Purpose |
|----------|---------|
| OPENAI_API_KEY | OpenAI access |
| ANTHROPIC_API_KEY | Anthropic access |
| ENABLE_GPT5_PREVIEW | If true and preview model provided, Cost Cutter uses GPTâ€‘5 preview |
| GPT5_PREVIEW_MODEL | Explicit GPTâ€‘5 preview model id |
| OPENAI_COST_CUTTER_MODEL | Override Cost Cutter model (if not using preview) |
| IDEA_KEYWORDS | Comma-separated keywords to bias topic selection |
| DEFAULT_MAX_TURNS | Default max turns |
| DEFAULT_MAX_DURATION_MINUTES | Default duration limit |
| DEBATE_INTENSITY | (Optional) Default debate intensity override |
| DIAGRAM_DETAIL_LEVEL | (Optional) Default diagram detail level override |

CLI `--keywords` temporarily overrides IDEA_KEYWORDS for that invocation.

Convergence: The system will inject a hint near the end to produce a FINAL DESIGN summary; completion requires that block.

*Built with â¤ï¸ for the software design community*

---

### ğŸ“š Project Index

For a consolidated list of all generated design sessions (topic, date, and diagram preview), see `PROJECTS_INDEX.md`.